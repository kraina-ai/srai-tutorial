{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Venturilo - Contextual count embedder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "Load dataset with *venturilo* bike stations (`data/venturilo_stations.json`) and convert *lat/lon* into a geometry column. Save it to `stations_gdf` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_raw = pd.read_json('../data/venturilo_stations.json')\n",
    "stations_gdf = gpd.GeoDataFrame(\n",
    "    stations_raw,\n",
    "    geometry=gpd.GeoSeries.from_xy(stations_raw[\"lon\"], stations_raw[\"lat\"]),\n",
    "    crs=\"EPSG:4326\",\n",
    ")\n",
    "stations_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading area of Warsaw in preparation for features download. Visualization of station location on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.regionalizers import geocode_to_region_gdf\n",
    "\n",
    "warsaw_region = geocode_to_region_gdf(\"Warsaw, PL\")\n",
    "m = warsaw_region.explore(tooltip=False, highlight=False, style_kwds={\"fillOpacity\": 0.3})\n",
    "stations_gdf.explore(m=m, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "Split the area of Warsaw into regions, for which we will be predicting stations location\n",
    "\n",
    "In this example we use H3 hierachical index and split the area into hexagons of size 9 (approx 500m in diameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.plotting import plot_regions\n",
    "from srai.regionalizers import H3Regionalizer\n",
    "\n",
    "regions_gdf = H3Regionalizer(resolution=9).transform(warsaw_region)\n",
    "plot_regions(regions_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Download the OSM tags which will be used to predict bicycle stations locations. But be honest, remove `\"amenity\": \"bicycle_rental\"` tag ;)\n",
    "\n",
    "You can use one of our predefined filters or create any for your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.loaders.osm_loaders.filters import GEOFABRIK_LAYERS, HEX2VEC_FILTER, BASE_OSM_GROUPS_FILTER\n",
    "from srai.loaders import OSMPbfLoader\n",
    "\n",
    "features_gdf = OSMPbfLoader().load(warsaw_region, GEOFABRIK_LAYERS)\n",
    "features_gdf = features_gdf[features_gdf[\"shopping\"] != \"amenity=bicycle_rental\"]\n",
    "features_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our features have not been associated with regions yet. We can use an *intersects* predicate and associate them with regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.joiners import IntersectionJoiner\n",
    "\n",
    "joined_features = IntersectionJoiner().transform(regions_gdf, features_gdf)\n",
    "joined_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "We have already accociated OSM features with regions. To train our model we have to join station locations with regions as well. Write the code which finds regions intersecting with station locations. Use those information to select positive and negative samples for classifier training (regions with and without stations). Remember that we wiil have to train model based on that, so make sure to do any neccessary undersampling to balance our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, join bike stations locations with regions, using `IntersectionJoiner`\n",
    "bikes_joint = IntersectionJoiner().transform(regions_gdf, stations_gdf)\n",
    "\n",
    "# For future visualizations, we will need to restore geometry column\n",
    "positive_samples = regions_gdf.join(bikes_joint, how=\"inner\")\n",
    "positive_samples = positive_samples.reset_index().drop(columns=[\"feature_id\"]).groupby(\"region_id\").agg(\"first\")  # this one is to remove duplicates\n",
    "positive_samples = positive_samples.reset_index().set_index(\"region_id\")\n",
    "positive_samples[\"is_positive\"] = True\n",
    "\n",
    "# Mark remaining regions as negative\n",
    "negative_samples = regions_gdf.copy()\n",
    "negative_samples[\"is_positive\"] = False\n",
    "negative_samples.loc[positive_samples.index, \"is_positive\"] = True\n",
    "negative_samples = negative_samples[~negative_samples[\"is_positive\"]]\n",
    "\n",
    "# Just to keep everything balanced - undersampling\n",
    "negative_samples = negative_samples.sample(n=3 * len(positive_samples), random_state=42)\n",
    "\n",
    "train_data = pd.concat([positive_samples, negative_samples])\n",
    "train_data.explore(\"is_positive\", cmap=\"cividis\", zoom_start=13, tiles=\"CartoDB positron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create embeddings for each region in our city (embeddings form outside of training data will be used for visualizations). Those will serve as our *Xs* for training, and *Ys* will be binary value if station is in the area or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.embedders import ContextualCountEmbedder\n",
    "from srai.neighbourhoods import H3Neighbourhood\n",
    "\n",
    "embedder = ContextualCountEmbedder(neighbourhood=H3Neighbourhood(), neighbourhood_distance=5, concatenate_vectors=True)\n",
    "embeddings = embedder.transform(regions_gdf=regions_gdf, features_gdf=features_gdf, joint_gdf=joined_features)\n",
    "X = embeddings.loc[train_data.index].to_numpy()\n",
    "Y = train_data[\"is_positive\"].astype(int).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "Select your favourite model and train a classifier for station locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=42)\n",
    "\n",
    "\n",
    "classifier = SVC(probability=True)\n",
    "classifier.fit(X_train, Y_train)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "Y_pred_proba = classifier.predict_proba(X_test)\n",
    "\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "\n",
    "Run predictions for all regions and prepare visualization on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.plotting import plot_numeric_data\n",
    "\n",
    "station_probas = classifier.predict_proba(embeddings.to_numpy())\n",
    "regions_gdf[\"station_proba\"] = station_probas[:, 1]\n",
    "m = plot_numeric_data(regions_gdf, \"station_proba\", colormap=\"Spectral_r\", opacity=0.5)\n",
    "stations_gdf.explore(m=m, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final task - transfer learning\n",
    "\n",
    "Now we have a model, which was trained on data from Warsaw. Select some other city, and run predictions on it. Let's see where to put BSS stations there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select area\n",
    "wroclaw_region = geocode_to_region_gdf('Wrocław, PL')\n",
    "\n",
    "# Split into regions\n",
    "wroclaw_regions_gdf = H3Regionalizer(resolution=9).transform(wroclaw_region)\n",
    "\n",
    "# Load OSM features (the same as for model training)\n",
    "wroclaw_features_gdf = OSMPbfLoader().load(wroclaw_region,GEOFABRIK_LAYERS)\n",
    "wroclaw_features_gdf = wroclaw_features_gdf[wroclaw_features_gdf[\"shopping\"] != \"amenity=bicycle_rental\"]\n",
    "\n",
    "# Wrocław has a BSS, so let's download station locations for reference\n",
    "from srai.loaders import OSMOnlineLoader\n",
    "wroclaw_stations = OSMOnlineLoader().load(wroclaw_region, {\"amenity\": \"bicycle_rental\"})\n",
    "\n",
    "# Get embeddings for regions\n",
    "wroclaw_joined_features = IntersectionJoiner().transform(wroclaw_regions_gdf, wroclaw_features_gdf)\n",
    "wroclaw_embeddings = embedder.transform(\n",
    "    regions_gdf=wroclaw_regions_gdf,\n",
    "    features_gdf=wroclaw_features_gdf,\n",
    "    joint_gdf=wroclaw_joined_features,\n",
    ")\n",
    "\n",
    "# Predict and visualize\n",
    "station_probas = classifier.predict_proba(wroclaw_embeddings.to_numpy())\n",
    "\n",
    "wroclaw_regions_gdf[\"station_proba\"] = station_probas[:, 1]\n",
    "m = plot_numeric_data(wroclaw_regions_gdf, \"station_proba\", colormap=\"Spectral_r\", opacity=0.5)\n",
    "\n",
    "wroclaw_stations.explore(m=m, color='black')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
