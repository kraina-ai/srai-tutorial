{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install srai[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pydeck as pdk\n",
    "import h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('../../data/trips_hexes.zip', \"r\") as zf:\n",
    "    for member in tqdm(zf.infolist(), desc=\"\"):\n",
    "        try:\n",
    "            zf.extract(member, 'data')\n",
    "        except zipfile.error:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_trips_h3 = pd.read_csv('../../data/trips_hexes.csv')\n",
    "print(taxi_trips_h3.min(), taxi_trips_h3.max())\n",
    "taxi_trips_h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3.get_resolution(taxi_trips_h3['start_hex'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_trips_h3.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_trips_h3['start_point'] = taxi_trips_h3['start_hex'].apply(h3.cell_to_latlng)\n",
    "taxi_trips_h3['end_point'] = taxi_trips_h3['end_hex'].apply(h3.cell_to_latlng)\n",
    "taxi_trips_h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_trips_h3['start_lat'], taxi_trips_h3['start_lon'] = zip(*taxi_trips_h3['start_point'])\n",
    "taxi_trips_h3['end_lat'], taxi_trips_h3['end_lon'] = zip(*taxi_trips_h3['end_point'])\n",
    "taxi_trips_h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_trips_h3[\"trips_normalized\"] = (\n",
    "    (taxi_trips_h3[\"trips\"] - taxi_trips_h3[\"trips\"].min())\n",
    "    / (taxi_trips_h3[\"trips\"].max() - taxi_trips_h3[\"trips\"].min())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_layer = pdk.Layer(\n",
    "    \"ArcLayer\",\n",
    "#     data=taxi_trips_h3.sample(frac=0.1),\n",
    "    data=taxi_trips_h3,\n",
    "    get_width=\"0.5 + trips_normalized * 9\",\n",
    "    get_source_position=[\"start_lon\", \"start_lat\"],\n",
    "    get_target_position=[\"end_lon\", \"end_lat\"],\n",
    "    get_tilt=15,\n",
    "    get_source_color=\"[0, 255, 0, 40 + trips_normalized * 215]\",\n",
    "    get_target_color=\"[0, 150, 255, 40 + trips_normalized * 215]\",\n",
    "    pickable=True,\n",
    "    auto_highlight=True,\n",
    ")\n",
    "\n",
    "view_state = pdk.ViewState(latitude=41.1493, longitude=-8.6111, bearing=45, pitch=65, zoom=10.5,)\n",
    "\n",
    "TOOLTIP_TEXT = {\"html\": \"{trips} trips <br /> Start of the trip in green; end of the trip in blue\"}\n",
    "pdk.Deck(arc_layer, initial_view_state=view_state, tooltip=TOOLTIP_TEXT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_hexes = set(taxi_trips_h3['start_hex'].unique()).union(taxi_trips_h3['end_hex'].unique())\n",
    "len(unique_hexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = [h3.cell_to_latlng(h3_cell)[::-1] for h3_cell in unique_hexes]\n",
    "coordinates[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_points = gpd.GeoDataFrame(geometry=gpd.GeoSeries.from_xy(*zip(*coordinates)), crs='EPSG:4326')\n",
    "unique_points.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.regionalizers import AdministrativeBoundaryRegionalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portugal_regionalizer = AdministrativeBoundaryRegionalizer(admin_level=7, clip_regions=False)\n",
    "\n",
    "municipalities = portugal_regionalizer.transform(unique_points)\n",
    "municipalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipalities.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_h3_resolution = h3.get_resolution(taxi_trips_h3['start_hex'].iloc[0])\n",
    "trip_h3_resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbours_distance = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.regionalizers import H3Regionalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portugal_h3_regions = H3Regionalizer(resolution=trip_h3_resolution).transform(municipalities)\n",
    "portugal_h3_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.loaders.osm_loaders import OSMPbfLoader\n",
    "from srai.loaders.osm_loaders.filters import GEOFABRIK_LAYERS\n",
    "from srai.h3 import ring_buffer_h3_regions_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffered_regions = ring_buffer_h3_regions_gdf(regions_gdf=portugal_h3_regions, distance=neighbours_distance)\n",
    "buffered_area = buffered_regions.unary_union\n",
    "gpd.GeoSeries([buffered_area], crs='EPSG:4326').explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = OSMPbfLoader()\n",
    "\n",
    "portugal_features = loader.load(buffered_area, GEOFABRIK_LAYERS)\n",
    "portugal_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portugal_features[portugal_features.geom_type != 'Point'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.joiners import IntersectionJoiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portugal_joint_features = IntersectionJoiner().transform(buffered_regions, portugal_features)\n",
    "portugal_joint_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.embedders import GeoVexEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geovex_embedder = GeoVexEmbedder(\n",
    "    target_features=GEOFABRIK_LAYERS,\n",
    "    embedding_size=50,\n",
    "    batch_size=128,\n",
    "    neighbourhood_radius=neighbours_distance,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.neighbourhoods import H3Neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portugal_h3_neighbourhood = H3Neighbourhood(buffered_regions)\n",
    "portugal_embeddings = geovex_embedder.fit_transform(\n",
    "    buffered_regions,\n",
    "    portugal_features,\n",
    "    portugal_joint_features,\n",
    "    portugal_h3_neighbourhood,\n",
    "    trainer_kwargs={\n",
    "        \"max_epochs\": 5,\n",
    "        \"accelerator\": (\n",
    "            \"cpu\" if torch.backends.mps.is_available() else \"auto\"\n",
    "        ),  # GeoVexEmbedder does not support MPS\n",
    "    },\n",
    ")\n",
    "portugal_embeddings = portugal_embeddings.loc[portugal_h3_regions.index]\n",
    "portugal_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "pca_embeddings = pca.fit_transform(portugal_embeddings)\n",
    "# make the embeddings into a dataframe\n",
    "pca_embeddings = pd.DataFrame(pca_embeddings, index=portugal_embeddings.index)\n",
    "\n",
    "# convert to RGB\n",
    "pca_embeddings = (\n",
    "    (pca_embeddings - pca_embeddings.min())\n",
    "    / (pca_embeddings.max() - pca_embeddings.min())\n",
    "    * 255\n",
    ").astype(int)\n",
    "\n",
    "# make the rgb array into a string\n",
    "pca_embeddings[\"rgb\"] = pca_embeddings.apply(\n",
    "    lambda row: f\"rgb({row[0]}, {row[1]}, {row[2]})\", axis=1\n",
    ")\n",
    "\n",
    "# porto_regions = portugal_h3_regions[\n",
    "#     portugal_h3_regions.intersects(\n",
    "#         municipalities.loc[[\"Porto\", \"Vila Nova de Gaia\", \"Matosinhos\"]].unary_union\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "color_dict = dict(\n",
    "    enumerate(portugal_h3_regions.index.map(pca_embeddings[\"rgb\"].to_dict()).to_list())\n",
    ")\n",
    "portugal_h3_regions.reset_index().reset_index().explore(\n",
    "    column=\"index\",\n",
    "    tooltip=\"region_id\",\n",
    "    tiles=\"CartoDB positron\",\n",
    "    legend=False,\n",
    "    cmap=lambda x: color_dict[x],\n",
    "    style_kwds=dict(color=\"#444\", opacity=0.0, fillOpacity=0.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(14,9))\n",
    "ax = fig.add_subplot(111, \n",
    "                     projection='3d')\n",
    " \n",
    "for idx in pca_embeddings.index:\n",
    "    ax.scatter(pca_embeddings.loc[idx][0],\n",
    "               pca_embeddings.loc[idx][1],\n",
    "               pca_embeddings.loc[idx][2],\n",
    "               s=60)\n",
    "\n",
    "ax.set_xlabel(\"PC1\", \n",
    "              fontsize=12)\n",
    "ax.set_ylabel(\"PC2\", \n",
    "              fontsize=12)\n",
    "ax.set_zlabel(\"PC3\", \n",
    "              fontsize=12)\n",
    " \n",
    "ax.view_init(30, 125)\n",
    "plt.title(\"3D PCA plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portugal_h3_index = portugal_embeddings.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_of_trips_per_hex = taxi_trips_h3.groupby('start_hex')['trips'].sum()\n",
    "sum_of_trips_per_hex.index.name = 'region_id'\n",
    "sum_of_trips_per_hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_trips_per_hex.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_trips_per_hex.quantile(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_trips_per_hex = sum_of_trips_per_hex.clip(0, sum_of_trips_per_hex.quantile(0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_trips_per_hex.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.plotting import plot_numeric_data\n",
    "plot_numeric_data(portugal_h3_regions, \"trips\", pd.DataFrame(sum_of_trips_per_hex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trips = portugal_embeddings.loc[sum_of_trips_per_hex.index].values\n",
    "y_trips = list(sum_of_trips_per_hex.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trips_train, X_trips_test, y_trips_train, y_trips_test = train_test_split(\n",
    "    X_trips, y_trips, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trips_binary = portugal_embeddings.loc[portugal_h3_index].values\n",
    "y_trips_binary = [\n",
    "    1 if h3_index in sum_of_trips_per_hex.index else 0 for h3_index in portugal_h3_index\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binary_train, X_binary_test, y_binary_train, y_binary_test = train_test_split(\n",
    "    X_trips_binary, y_trips_binary, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_classifier = XGBClassifier(n_estimators=1000)\n",
    "binary_classifier.fit(X_binary_train, y_binary_train)\n",
    "y_binary_pred = binary_classifier.predict(X_binary_test)\n",
    "\n",
    "print(classification_report(y_binary_test, y_binary_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_regressor = XGBRegressor(n_estimators=1000)\n",
    "trips_regressor.fit(X_trips_train, y_trips_train)\n",
    "y_trips_pred = trips_regressor.predict(X_trips_test)\n",
    "\n",
    "print(\n",
    "    r2_score(y_trips_test, y_trips_pred),\n",
    "    mean_absolute_error(y_trips_test, y_trips_pred),\n",
    "    mean_absolute_percentage_error(y_trips_test, y_trips_pred),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numeric_data(portugal_h3_regions, 0, pd.DataFrame(trips_regressor.predict(X_trips), index=pd.Index(sum_of_trips_per_hex.index, name='region_id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portugal_h3_regions['trip_binary'] = [\n",
    "    1 if h3_index in sum_of_trips_per_hex.index else 0 for h3_index in portugal_h3_regions.index\n",
    "]\n",
    "portugal_h3_regions.plot('trip_binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portugal_h3_regions['trip_binary_predicted'] = binary_classifier.predict(portugal_embeddings.loc[portugal_h3_regions.index].values)\n",
    "portugal_h3_regions.plot('trip_binary_predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List\n",
    "\n",
    "from torch import nn\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "def weighted_mse_loss(input, target, weight):\n",
    "    return torch.sum(weight * (input - target) ** 2)\n",
    "\n",
    "class TripPredictorModel(LightningModule):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.nn_model = nn.Sequential(\n",
    "            nn.Linear(50, 50),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(50, 50),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: \"torch.Tensor\") -> \"torch.Tensor\":\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "        \"\"\"\n",
    "        embedding: \"torch.Tensor\" = self.nn_model(x)\n",
    "        return embedding\n",
    "\n",
    "    def configure_optimizers(self) -> \"torch.optim.Optimizer\":\n",
    "        \"\"\"Configure optimizer.\"\"\"\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch: List[\"torch.Tensor\"], batch_idx: Any) -> \"torch.Tensor\":\n",
    "        \"\"\"\n",
    "        Training step.\n",
    "\n",
    "        Args:\n",
    "            batch (torch.Tensor): Batch.\n",
    "            batch_idx (Any): Batch index.\n",
    "        \"\"\"\n",
    "        x, y, weight = batch\n",
    "        y_pred = self.nn_model(x)\n",
    "        loss = weighted_mse_loss(y_pred, y, weight)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TripsDataset(Dataset):\n",
    "    def __init__(self, start_embeddings, end_embeddings, trips):\n",
    "        self.start_embeddings = torch.Tensor(start_embeddings)\n",
    "        self.end_embeddings = torch.Tensor(end_embeddings)\n",
    "        self.trips = torch.Tensor(trips.reshape((len(trips), 1)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.start_embeddings[index]\n",
    "        y = self.end_embeddings[index]\n",
    "        weight = self.trips[index]\n",
    "        return x, y, weight\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.start_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_hexes = taxi_trips_h3['start_hex']\n",
    "end_hexes = taxi_trips_h3['end_hex']\n",
    "no_trips = taxi_trips_h3['trips']\n",
    "\n",
    "trips_dataset = TripsDataset(\n",
    "    start_embeddings=portugal_embeddings.loc[start_hexes].to_numpy(),\n",
    "    end_embeddings=portugal_embeddings.loc[end_hexes].to_numpy(),\n",
    "    trips=no_trips.to_numpy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "trainer_kwargs = {\n",
    "    # \"max_epochs\": 50, # uncomment for a longer training\n",
    "    \"max_epochs\": 25,\n",
    "    # \"accelerator\": \"cpu\",\n",
    "}\n",
    "\n",
    "dataloader = DataLoader(trips_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "trip_predictor_model = TripPredictorModel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(**trainer_kwargs)\n",
    "trainer.fit(trip_predictor_model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trips(\n",
    "    h3_embeddings_gdf,\n",
    "    binary_classifier,\n",
    "    trips_regressor,\n",
    "    trip_destination_predictor,\n",
    "    n = 100\n",
    "):\n",
    "    h3_index = h3_embeddings_gdf.index\n",
    "    h3_embeddings = h3_embeddings_gdf.values\n",
    "    predicted_trips_binary = binary_classifier.predict(h3_embeddings)\n",
    "    predicted_trips_number = trips_regressor.predict(h3_embeddings).clip(min=0)\n",
    "    predicted_destinations_embeddings = trip_destination_predictor(torch.Tensor(h3_embeddings)).detach().numpy()\n",
    "    \n",
    "    annoy_index = AnnoyIndex(h3_embeddings.shape[1], \"angular\")\n",
    "\n",
    "    for idx in range(len(h3_index)):\n",
    "        annoy_index.add_item(idx, h3_embeddings[idx])\n",
    "\n",
    "    annoy_index.build(100, n_jobs=-1)\n",
    "    \n",
    "    trip_pairs = []\n",
    "    for idx in tqdm(range(len(h3_index)), total=len(h3_index)):\n",
    "        if predicted_trips_binary[idx] == 0:\n",
    "            continue\n",
    "        \n",
    "        trips_number = predicted_trips_number[idx]\n",
    "        \n",
    "        if trips_number == 0:\n",
    "            continue\n",
    "\n",
    "        trip_destination_embedding = predicted_destinations_embeddings[idx]\n",
    "        nearest_neighbours_ids, distances = annoy_index.get_nns_by_vector(\n",
    "            trip_destination_embedding,\n",
    "            n=n,\n",
    "            include_distances=True,\n",
    "        )\n",
    "        nearest_neighbours_h3s = h3_index[nearest_neighbours_ids]\n",
    "        weights = [1 - distance for distance in distances]\n",
    "        total_weight = sum(weights)\n",
    "        \n",
    "        start_index = h3_index[idx]\n",
    "        for nearest_neighbour, weight in zip(nearest_neighbours_h3s, weights):\n",
    "            trip_pairs.append(\n",
    "                dict(start_hex=start_index, end_hex=nearest_neighbour, trips=trips_number * weight / total_weight)\n",
    "            )\n",
    "            \n",
    "    predicted_trips = pd.DataFrame(trip_pairs)\n",
    "    predicted_trips[\"start_point\"] = predicted_trips[\"start_hex\"].apply(h3.cell_to_latlng)\n",
    "    predicted_trips[\"end_point\"] = predicted_trips[\"end_hex\"].apply(h3.cell_to_latlng)\n",
    "    predicted_trips[\"start_lat\"], predicted_trips[\"start_lon\"] = zip(\n",
    "        *predicted_trips[\"start_point\"]\n",
    "    )\n",
    "    predicted_trips[\"end_lat\"], predicted_trips[\"end_lon\"] = zip(\n",
    "        *predicted_trips[\"end_point\"]\n",
    "    )\n",
    "    predicted_trips[\"trips_normalized\"] = (\n",
    "        (predicted_trips[\"trips\"] - predicted_trips[\"trips\"].min())\n",
    "        / (predicted_trips[\"trips\"].max() - predicted_trips[\"trips\"].min())\n",
    "    )\n",
    "    return predicted_trips\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_trips = generate_trips(portugal_embeddings, binary_classifier, trips_regressor, trip_predictor_model, n=10)\n",
    "predicted_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_layer = pdk.Layer(\n",
    "    \"ArcLayer\",\n",
    "    data=predicted_trips,\n",
    "    get_width=\"0.5 + trips_normalized * 9\",\n",
    "    get_source_position=[\"start_lon\", \"start_lat\"],\n",
    "    get_target_position=[\"end_lon\", \"end_lat\"],\n",
    "    get_tilt=15,\n",
    "    get_source_color=\"[0, 255, 0, 40 + trips_normalized * 215]\",\n",
    "    get_target_color=\"[0, 150, 255, 40 + trips_normalized * 215]\",\n",
    "    pickable=True,\n",
    "    auto_highlight=True,\n",
    ")\n",
    "\n",
    "view_state = pdk.ViewState(latitude=41.1493, longitude=-8.6111, bearing=45, pitch=65, zoom=10.5,)\n",
    "\n",
    "TOOLTIP_TEXT = {\"html\": \"Predicted trips {trips} <br /> Start of the trip in green; end of the trip in blue\"}\n",
    "pdk.Deck(arc_layer, initial_view_state=view_state, tooltip=TOOLTIP_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.regionalizers import geocode_to_region_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warsaw_region = geocode_to_region_gdf(\"Warsaw, PL\")\n",
    "warsaw_h3_regions = H3Regionalizer(resolution=trip_h3_resolution).transform(warsaw_region)\n",
    "\n",
    "buffered_warsaw_regions = ring_buffer_h3_regions_gdf(regions_gdf=warsaw_h3_regions, distance=neighbours_distance)\n",
    "buffered_warsaw_area = buffered_warsaw_regions.unary_union\n",
    "\n",
    "warsaw_features = loader.load(buffered_warsaw_area, GEOFABRIK_LAYERS)\n",
    "\n",
    "warsaw_joint_features = IntersectionJoiner().transform(buffered_warsaw_regions, warsaw_features)\n",
    "\n",
    "warsaw_embeddings = geovex_embedder.transform(\n",
    "    buffered_warsaw_regions,\n",
    "    warsaw_features,\n",
    "    warsaw_joint_features,\n",
    ")\n",
    "warsaw_embeddings = warsaw_embeddings.loc[warsaw_h3_regions.index]\n",
    "\n",
    "predicted_warsaw_trips = generate_trips(warsaw_embeddings, binary_classifier, trips_regressor, trip_predictor_model, n=10)\n",
    "predicted_warsaw_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_layer = pdk.Layer(\n",
    "    \"ArcLayer\",\n",
    "    data=predicted_warsaw_trips,\n",
    "    get_width=\"0.5 + trips_normalized * 9\",\n",
    "    get_source_position=[\"start_lon\", \"start_lat\"],\n",
    "    get_target_position=[\"end_lon\", \"end_lat\"],\n",
    "    get_tilt=15,\n",
    "    get_source_color=\"[0, 255, 0, 40 + trips_normalized * 215]\",\n",
    "    get_target_color=\"[0, 150, 255, 40 + trips_normalized * 215]\",\n",
    "    pickable=True,\n",
    "    auto_highlight=True,\n",
    ")\n",
    "\n",
    "view_state = pdk.ViewState(latitude=52.2317, longitude=21.0064, bearing=45, pitch=65, zoom=10.5)\n",
    "\n",
    "TOOLTIP_TEXT = {\"html\": \"Predicted trips {trips} <br /> Start of the trip in green; end of the trip in blue\"}\n",
    "pdk.Deck(arc_layer, initial_view_state=view_state, tooltip=TOOLTIP_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
