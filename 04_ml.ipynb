{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"main-title\">\n",
    "<h1>Machine Learning Applications</h1>\n",
    "<p>Transfer learning and clustering</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transfer learning with bicycle rental stations\n",
    "\n",
    "In this part we will see:\n",
    "* How to use a pre-trained hex2vec model with srai\n",
    "* How to train classification model based on srai embeddings\n",
    "* How to use srai to gather training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# srai components used in this lesson\n",
    "from srai.loaders import OSMOnlineLoader, OSMPbfLoader\n",
    "from srai.regionalizers import geocode_to_region_gdf\n",
    "from srai.joiners import IntersectionJoiner\n",
    "from srai.embedders import Hex2VecEmbedder\n",
    "from srai.regionalizers import H3Regionalizer\n",
    "\n",
    "# classification model using scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from utils import CB_SAFE_PALLETE\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_CITY = \"WrocÅ‚aw, Poland\"\n",
    "TARGET_CITY = \"Basel, Switzerland\"\n",
    "H3_RESOLUTION = 10\n",
    "\n",
    "bike_stations_osm_tag = {\"amenity\": \"bicycle_rental\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_area = geocode_to_region_gdf(SOURCE_CITY)\n",
    "target_area = geocode_to_region_gdf(TARGET_CITY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading bike rental stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = OSMOnlineLoader()\n",
    "stations = loader.load(source_area, bike_stations_osm_tag)\n",
    "stations.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained embedding model\n",
    "\n",
    "We use pre-trained hex2vec model. This one was trained by us on all polish cities with 50k+ inhabitants. Models are available for download, link in [our repo](https://github.com/kraina-ai/srai#pre-trained-models-usage). For this tutorial, model for resoulution 10 is already downloaded and placed in `models` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = Hex2VecEmbedder.load(f\"models/hex2vec_{H3_RESOLUTION}_poland_50k\")\n",
    "embedder.expected_output_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to translate those features to OSM tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_osm_tags = {}\n",
    "\n",
    "for element in embedder.expected_output_features:\n",
    "    key, value = element.split('_', 1)\n",
    "    if key not in embedder_osm_tags:\n",
    "        embedder_osm_tags[key] = [value]\n",
    "    else:\n",
    "        embedder_osm_tags[key].append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load features from OSM and prepare regions\n",
    "\n",
    "We need to load features to calculate embeddings for our cities. We will use OSMPbfLoader this time, since it is faster than OSMOnlineLoader when we have a lot of tags to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load features\n",
    "train_features = OSMPbfLoader().load(source_area, embedder_osm_tags)\n",
    "# split into regions\n",
    "train_regions = H3Regionalizer(resolution=H3_RESOLUTION).transform(source_area)\n",
    "# join regions and features\n",
    "train_joint = IntersectionJoiner().transform(train_regions, train_features)\n",
    "# calculate embeddings\n",
    "train_embeddings = embedder.transform(train_regions, train_features, train_joint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign bike rental stations to regions to create training data for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_joint = IntersectionJoiner().transform(train_regions, stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select regions with stations as positive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_samples = train_regions.join(bikes_joint, how=\"inner\")\n",
    "positive_samples = positive_samples.reset_index().drop(columns=[\"feature_id\"]).set_index(\"region_id\")\n",
    "positive_samples[\"is_positive\"] = True\n",
    "len(positive_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now remaining regions are negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_samples = train_regions.copy()\n",
    "negative_samples[\"is_positive\"] = False\n",
    "negative_samples.loc[positive_samples.index, \"is_positive\"] = True\n",
    "negative_samples = negative_samples[~negative_samples[\"is_positive\"]]\n",
    "len(negative_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very imbalanced! Let's undersample to make it possible to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_undersampled = negative_samples.sample(n=3 * len(positive_samples), random_state=42)\n",
    "negative_undersampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see training data on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([positive_samples, negative_undersampled])\n",
    "train_data.explore(\"is_positive\", cmap=CB_SAFE_PALLETE, zoom_start=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_embeddings.loc[train_data.index].to_numpy()\n",
    "y = train_data[\"is_positive\"].astype(int).to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(probability=True)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred_proba = classifier.predict_proba(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer knowledge to Basel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat embedding for target city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_regions = H3Regionalizer(resolution=10).transform(target_area)\n",
    "target_features = OSMPbfLoader().load(target_area, embedder_osm_tags)\n",
    "target_joint = IntersectionJoiner().transform(target_regions, target_features)\n",
    "target_embeddings = embedder.transform(target_regions, target_features, target_joint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now find regions with high score for station location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_probas = classifier.predict_proba(target_embeddings.to_numpy())\n",
    "\n",
    "target_regions[\"add_station\"] = station_probas[:, 1] > 0.7\n",
    "target_regions.explore(\"add_station\", cmap=CB_SAFE_PALLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Way better results\n",
    "\n",
    "Kamil's past project took this task more seriously. He used larger selection of cities and obtained great results. See them here:\n",
    "\n",
    "https://t.ly/gPEt9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highway2Vec Clustering and similarity search\n",
    "\n",
    "In this part we will see:\n",
    "<!-- * How to use a pre-trained hex2vec model with srai\n",
    "* How to train classification model based on srai embeddings\n",
    "* How to use srai to gather training data -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "rise": {
   "controls": false,
   "enable_chalkboard": true,
   "footer": "<h3 class='footer-title'>Visit our research group at <code>kraina.ai</code></h3>",
   "header": "<h3 class='header-title'>SRAI Tutorial - ML Capabilities</h3><div class='header-images'><img src='assets/srai-logo-transparent.png'/></div>",
   "progress": true,
   "scroll": true,
   "slideNumber": false,
   "theme": "simple",
   "width": 1280
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
